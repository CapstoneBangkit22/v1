{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"integrate_with_model_new_fixed.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Text Recognition**"],"metadata":{"id":"HX6fKfzSZAes"}},{"cell_type":"markdown","source":["Setting up\n","\n","Intalling tesseract for extracting text"],"metadata":{"id":"fTcMnqm6_jZO"}},{"cell_type":"code","source":["!sudo apt install tesseract-ocr\n","!pip install pytesseract"],"metadata":{"id":"YRSkItu6fhvo","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"04255c4e-0047-437f-f9fb-f3685fed6c0b","executionInfo":{"status":"ok","timestamp":1655019003689,"user_tz":-420,"elapsed":12270,"user":{"displayName":"Tabitha Hanna M2003F0141","userId":"01554359227116500543"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 4,795 kB of archives.\n","After this operation, 15.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n","Fetched 4,795 kB in 1s (4,742 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 155632 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n","Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n","Collecting Pillow>=8.0.0\n","  Downloading Pillow-9.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 14.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n","Installing collected packages: Pillow, pytesseract\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Pillow-9.1.1 pytesseract-0.3.9\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["Because file is stored in drive, we have to mount drive first."],"metadata":{"id":"heF1RwFBeJK0"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ovaTlDb1Z1-9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"61af5290-0dcd-45f0-bc35-ec8c9862b7c4","executionInfo":{"status":"ok","timestamp":1655019104880,"user_tz":-420,"elapsed":51935,"user":{"displayName":"Tabitha Hanna M2003F0141","userId":"01554359227116500543"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!which tesseract #to know the dir for Pytesseract is stored"],"metadata":{"id":"6Fap8-0dRnlL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Installing keras and numpy"],"metadata":{"id":"z01tCZTgZ72L"}},{"cell_type":"code","source":["!pip install keras\n","!pip install numpy"],"metadata":{"id":"Wm_U0bXZkFGi","executionInfo":{"status":"ok","timestamp":1655019122397,"user_tz":-420,"elapsed":4773,"user":{"displayName":"Tabitha Hanna M2003F0141","userId":"01554359227116500543"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9005034a-f4fd-4c0e-9f50-9de87d4c4f49"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"]}]},{"cell_type":"markdown","source":["Import libraries and display image file"],"metadata":{"id":"nTPIXlmyecoq"}},{"cell_type":"code","source":["import pytesseract\n","import cv2\n","import matplotlib.pylab as plt\n","\n","pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract' #we know from the !which tesseract command\n","\n","img = cv2.imread('/content/drive/MyDrive/Bangkit - Capstone/img_for_testing/test2.png')\n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","\n","plt.title('Show Image')\n","plt.imshow(img)"],"metadata":{"id":"RIxT75YGi-aN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#to know the image size\n","hImg, wImg,_ = img.shape\n","img.shape"],"metadata":{"id":"Ec8W17mSQCVT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Image Cleaning** "],"metadata":{"id":"6a3R0cLmz7YI"}},{"cell_type":"code","source":["img = cv2.bilateralFilter(img, 5, 55, 60)\n","plt.imshow(img)\n"],"metadata":{"id":"e0kVqPy1z4un"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Text detection\n","\n","detect = (pytesseract.image_to_data(img))\n","for x, detect in enumerate(detect.splitlines()):\n","  if x != 0:\n","    detect = detect.split()\n","    print(detect)\n","    if len(detect) == 12:\n","      x, y, w, h = int(detect[6]), int(detect[7]), int(detect[8]), int(detect[9])\n","      cv2.rectangle(img, (x,y), (w+x, h+y), (0,0,255), 2)\n","      #cv2.putText(img, detect[11], (x,y), cv2.FONT_HERSHEY_PLAIN, 1, (50,50,255), 3)\n","\n","print('Text detection')\n","plt.imshow(img)"],"metadata":{"id":"OFh8zKo0OLsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Recognize text\n","\n","img_to_char = pytesseract.image_to_string(img)\n","print(img_to_char)"],"metadata":{"id":"w617U-rPb6sW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Prediction**"],"metadata":{"id":"DYyk8dCycDug"}},{"cell_type":"code","source":["import csv\n","import random\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import matplotlib.pyplot as plt\n","from scipy.stats import linregress\n","from tensorflow.keras.preprocessing.text import Tokenizer"],"metadata":{"id":"rmZuEi1DcKXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_WORDS = 1000\n","EMBEDDING_DIM = 100\n","MAXLEN = 16\n","PADDING = 'post'\n","OOV_TOKEN = \"<OOV>\"\n","TRAINING_SPLIT = .8\n","TRUNCATING = 'post'\n","MAX_EXAMPLES = 160000"],"metadata":{"id":"RQXO6gExcLoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fit_tokenizer(train_sentences, num_words, oov_token):\n","  tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=OOV_TOKEN)\n","  tokenizer.fit_on_texts(train_sentences)\n","  return tokenizer"],"metadata":{"id":"wInP42CacMoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seq_and_pad(sentences, tokenizer, padding, maxlen):\n","  sequences = tokenizer.texts_to_sequences(sentences)\n","  padded_sequences = pad_sequences(sequences, maxlen=MAXLEN, padding=PADDING)\n","  \n","  return padded_sequences"],"metadata":{"id":"qf8VmPemcO-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = img_to_char\n","text = text.lower()\n","text1 = text.split()"],"metadata":{"id":"mrJ7WQAOcP2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = fit_tokenizer(text, NUM_WORDS, OOV_TOKEN)\n","word_index = tokenizer.word_index\n","\n","print(f\"Vocabulary contains {len(word_index)} words\\n\")\n","print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")"],"metadata":{"id":"Xf_3J431cQ5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Bangkit - Capstone/model.h5\")\n","new_model.summary()"],"metadata":{"id":"Ntsf6zb0cSVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for x in range(len(text1)) :\n","  word_token = seq_and_pad(text1[x], tokenizer, PADDING, MAXLEN)\n","  predict = new_model.predict(word_token)"],"metadata":{"id":"iv8F2SGXcTrq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(predict)"],"metadata":{"id":"vikdvS3McUuA"},"execution_count":null,"outputs":[]}]}